{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrLB80TapPi/FLZDpw4t3d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujiraa/bsc_dpdm22/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NH41ajBMVSrp"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2VXhihwtWEqW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCd_ctarWT9Y",
        "outputId": "c97f935e-e3dd-4ca2-f955-bcea859caf1b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "        ...,\n",
              "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
              " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
              " 'frame': None,\n",
              " 'feature_names': ['pixel_0_0',\n",
              "  'pixel_0_1',\n",
              "  'pixel_0_2',\n",
              "  'pixel_0_3',\n",
              "  'pixel_0_4',\n",
              "  'pixel_0_5',\n",
              "  'pixel_0_6',\n",
              "  'pixel_0_7',\n",
              "  'pixel_1_0',\n",
              "  'pixel_1_1',\n",
              "  'pixel_1_2',\n",
              "  'pixel_1_3',\n",
              "  'pixel_1_4',\n",
              "  'pixel_1_5',\n",
              "  'pixel_1_6',\n",
              "  'pixel_1_7',\n",
              "  'pixel_2_0',\n",
              "  'pixel_2_1',\n",
              "  'pixel_2_2',\n",
              "  'pixel_2_3',\n",
              "  'pixel_2_4',\n",
              "  'pixel_2_5',\n",
              "  'pixel_2_6',\n",
              "  'pixel_2_7',\n",
              "  'pixel_3_0',\n",
              "  'pixel_3_1',\n",
              "  'pixel_3_2',\n",
              "  'pixel_3_3',\n",
              "  'pixel_3_4',\n",
              "  'pixel_3_5',\n",
              "  'pixel_3_6',\n",
              "  'pixel_3_7',\n",
              "  'pixel_4_0',\n",
              "  'pixel_4_1',\n",
              "  'pixel_4_2',\n",
              "  'pixel_4_3',\n",
              "  'pixel_4_4',\n",
              "  'pixel_4_5',\n",
              "  'pixel_4_6',\n",
              "  'pixel_4_7',\n",
              "  'pixel_5_0',\n",
              "  'pixel_5_1',\n",
              "  'pixel_5_2',\n",
              "  'pixel_5_3',\n",
              "  'pixel_5_4',\n",
              "  'pixel_5_5',\n",
              "  'pixel_5_6',\n",
              "  'pixel_5_7',\n",
              "  'pixel_6_0',\n",
              "  'pixel_6_1',\n",
              "  'pixel_6_2',\n",
              "  'pixel_6_3',\n",
              "  'pixel_6_4',\n",
              "  'pixel_6_5',\n",
              "  'pixel_6_6',\n",
              "  'pixel_6_7',\n",
              "  'pixel_7_0',\n",
              "  'pixel_7_1',\n",
              "  'pixel_7_2',\n",
              "  'pixel_7_3',\n",
              "  'pixel_7_4',\n",
              "  'pixel_7_5',\n",
              "  'pixel_7_6',\n",
              "  'pixel_7_7'],\n",
              " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
              "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
              "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
              "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
              "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
              "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
              "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
              "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
              "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
              " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 28\n",
        "plt.gray()\n",
        "plt.matshow(digits.images[ind])\n",
        "print(digits.target[ind])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "MpiJoazeWbBZ",
        "outputId": "9a2cec39-9e6f-4b3a-82fa-0d80160dd9ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quiz 3 march\n",
        "- แบ่ง data ออกเป็น 80%(train) 20%(test) โดยใช้ random_state = เลขกลุ่ม shuffle=True\n",
        "- หา parameters ที่ดีที่สุด (K (1,3,5), Distance_weighted(yes/no)) ด้วย 10-fold-cross-validation\n",
        "- test parameters ที่ดีที่สุด กับ test data"
      ],
      "metadata": {
        "id": "YSUNbCekXPvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "WeHt46AyZJ3P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=4) #แบ่ง train test"
      ],
      "metadata": {
        "id": "o9V6gCn9dqif"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the KNeighborsClassifier class\n",
        "#knn1 = KNeighborsClassifier(n_neighbors=1) \n",
        "\n",
        "# Train the model using the training data\n",
        "#knn1.fit(X_train, y_train)\n",
        "\n",
        "# Use the model to make predictions on the testing data\n",
        "#y_pred = knn1.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "#scores = cross_val_score(knn1, digits.data, digits.target, cv=10)\n",
        "#mean_accuracy = scores.mean()\n",
        "#print(\"Accuracy:\", mean_accuracy)"
      ],
      "metadata": {
        "id": "enUccfn0enZs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# เฉลย"
      ],
      "metadata": {
        "id": "C10z6QuQgWoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ],
      "metadata": {
        "id": "ddGZsgPWkPOB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=4)"
      ],
      "metadata": {
        "id": "2qyPIXWekSf8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "6O9P2T0RkU07"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model selection"
      ],
      "metadata": {
        "id": "NFPvRiyLkc3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model 1 (K=1, weighted)\n",
        "knn_distance = KNeighborsClassifier(n_neighbors=1, weights='distance')\n",
        "scores = cross_val_score(knn_distance, X_train, y_train, cv=10)\n",
        "print(\"Mean Cross-Validation Score: K1weighted\", scores.mean())\n",
        "\n",
        "# model 2 (K=3, weighted)\n",
        "knn_distance = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "scores = cross_val_score(knn_distance, X_train, y_train, cv=10)\n",
        "print(\"Mean Cross-Validation Score: K3weighted\", scores.mean())\n",
        "\n",
        "# model 3 (K=5, weighted) \n",
        "knn_distance = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
        "scores = cross_val_score(knn_distance, X_train, y_train, cv=10)\n",
        "print(\"Mean Cross-Validation Score: K5weighted\", scores.mean())\n",
        "\n",
        "# model 4 (K=1, no weighted)\n",
        "knn_distance = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
        "scores = cross_val_score(knn_distance, X_train, y_train, cv=10)\n",
        "print(\"Mean Cross-Validation Score: K1NOweighted\", scores.mean())\n",
        "\n",
        "# model 5 (K=3, no weighted)\n",
        "knn_distance = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
        "scores = cross_val_score(knn_distance, X_train, y_train, cv=10)\n",
        "print(\"Mean Cross-Validation Score: K3NOweighted\", scores.mean())\n",
        "\n",
        "# model 6 (K=5, no weighted)\n",
        "knn_distance = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
        "scores = cross_val_score(knn_distance, X_train, y_train, cv=10)\n",
        "print(\"Mean Cross-Validation Score: KNOweighted\", scores.mean())"
      ],
      "metadata": {
        "id": "Qi2cMkWngVo-",
        "outputId": "4649de03-ce12-4d96-b6df-423435d3d6a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Cross-Validation Score: K1weighted 0.9853875291375293\n",
            "Mean Cross-Validation Score: K3weighted 0.9860819735819737\n",
            "Mean Cross-Validation Score: K5weighted 0.9881750194250195\n",
            "Mean Cross-Validation Score: K1NOweighted 0.9853875291375293\n",
            "Mean Cross-Validation Score: K3NOweighted 0.9860819735819737\n",
            "Mean Cross-Validation Score: KNOweighted 0.9881750194250195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate with test set"
      ],
      "metadata": {
        "id": "96xUFqarkeYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_distance = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
        "\n",
        "knn_distance.fit(X_train,y_train)\n",
        "\n",
        "y_pred = knn_distance.predict(X_test)"
      ],
      "metadata": {
        "id": "zaKDolJwkg-E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assume y_true and y_pred are the true and predicted labels, respectively\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score\n",
        "print(\"Accuracy score: \", accuracy)"
      ],
      "metadata": {
        "id": "NP7HmYkZkmKi",
        "outputId": "3cfc9f3d-1805-4a78-babd-1def6ea65aca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:  0.9861111111111112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW7\n",
        "- หาโมเดลที่ดีที่สุด จาก DT,NaiveBayes,KNN,ANN โดย เปรียบเทียบ อย่างละสอง parameter sets"
      ],
      "metadata": {
        "id": "rngnz0mlU5G3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DecisionTree"
      ],
      "metadata": {
        "id": "Sbqih5wUVE21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "X = digits['data']\n",
        "y = digits['target']\n",
        "# train_test_split จะใช้สุ่มแบ่ง X และ y เป็นชุดข้อมูลฝึกและชุดข้อมูลทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4, shuffle=True) #test_size=0.2 คือ 20% \n",
        "#กำหนด test_size เป็น 0.2 และกำหนด random_state เป็น 4 เพื่อให้การแบ่งชุดข้อมูลสามารถทำซ้ำได้และ shuffle เป็น True เพื่อสลับลำดับข้อมูลก่อนแบ่งชุด\n",
        "\n",
        "# Define parameter set 1\n",
        "params1 = {'criterion': 'gini', 'max_depth': 3}\n",
        "\n",
        "# Define parameter set 2\n",
        "params2 = {'criterion': 'entropy', 'max_depth': 5}\n",
        "\n",
        "# Create decision tree with parameter set 1\n",
        "dt1 = DecisionTreeClassifier(criterion=params1['criterion'], max_depth=params1['max_depth'])\n",
        "\n",
        "# Create decision tree with parameter set 2\n",
        "dt2 = DecisionTreeClassifier(criterion=params2['criterion'], max_depth=params2['max_depth'])\n",
        "\n",
        "# Evaluate the decision tree with parameter set 1\n",
        "accuracy1 = cross_val_score(dt1, digits.data, digits.target, cv=5).mean()\n",
        "\n",
        "# Evaluate the decision tree with parameter set 2\n",
        "accuracy2 = cross_val_score(dt2, digits.data, digits.target, cv=5).mean()\n",
        "\n",
        "# Compare the accuracies of the two models and choose the one with the highest accuracy\n",
        "if accuracy1 > accuracy2:\n",
        "    print(\"DT1 Parameter set 1 is better with an accuracy of\", accuracy1)\n",
        "else:\n",
        "    print(\"DT2 Parameter set 2 is better with an accuracy of\", accuracy2)\n",
        "\n",
        "# ค่า accuracy จะถูกคำนวณด้วย cross_val_score"
      ],
      "metadata": {
        "id": "tdFkMUrSU_Rg",
        "outputId": "b5f9a687-527b-464b-ca09-ebb531d456b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT2 Parameter set 2 is better with an accuracy of 0.7329371711544415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NaiveBayes"
      ],
      "metadata": {
        "id": "-YdDcwpWWgjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = digits['data']\n",
        "y = digits['target']\n",
        "# train_test_split จะใช้สุ่มแบ่ง X และ y เป็นชุดข้อมูลฝึกและชุดข้อมูลทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4, shuffle=True) #test_size=0.2 คือ 20% \n",
        "#กำหนด test_size เป็น 0.2 และกำหนด random_state เป็น 4 เพื่อให้การแบ่งชุดข้อมูลสามารถทำซ้ำได้และ shuffle เป็น True  สลับลำดับข้อมูลก่อนแบ่งชุดเพื่อลดผลกระทบจากการจัดเรียงข้อมูล\n",
        "\n",
        "# Parameter Set 1: สร้างโมเดล Multinomial Naive Bayes โดยกำหนด alpha=1.0 เพื่อใช้ Laplace smoothing\n",
        "mnb = MultinomialNB(alpha=1.0)\n",
        "mnb.fit(X_train, y_train)\n",
        "# คำนวณค่า accuracy ของโมเดลด้วยชุดข้อมูลทดสอบ (X_test, y_test)\n",
        "mnb_score = mnb.score(X_test, y_test)\n",
        "\n",
        "# Parameter Set 2: สร้างโมเดล Gaussian Naive Bayes โดยไม่ใช้ Smoothing\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "gnb_score = gnb.score(X_test, y_test)\n",
        "\n",
        "# Print best model based on test set accuracy\n",
        "if mnb_score > gnb_score:\n",
        "    print(\"Best Model: Multinomial Naive Bayes with Laplace Smoothing\")\n",
        "    print(\"Test Accuracy: %0.2f\" % mnb_score)\n",
        "else:\n",
        "    print(\"Best Model: Gaussian Naive Bayes without Smoothing\")\n",
        "    print(\"Test Accuracy: %0.2f\" % gnb_score)"
      ],
      "metadata": {
        "id": "6VprrUEYWf2m",
        "outputId": "a7c17d93-ae36-4801-9f82-124b10d61434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: Multinomial Naive Bayes with Laplace Smoothing\n",
            "Test Accuracy: 0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- หลังจากที่ได้คำนวณค่าความแม่นยำของ Multinomial Naive Bayes และ Gaussian Naive Bayes จากข้อมูล test set แล้ว\n",
        "- เงื่อนไขที่กำหนดใน if คือ mnb_score > gnb_score ซึ่งหมายความว่าถ้าโมเดล Multinomial Naive Bayes มีค่าความแม่นยำสูงกว่าโมเดล Gaussian Naive Bayes จะเข้าเงื่อนไข if\n",
        "- และทำงานในส่วนของคำสั่งที่อยู่ภายใน if โดยพิมพ์ข้อความ \"Best Model: Multinomial Naive Bayes with Laplace Smoothing\" และค่าความแม่นยำของโมเดล Multinomial Naive Bayes ที่ได้จากการทดสอบ\n",
        "- แต่ถ้าเงื่อนไขเป็นเท็จจะเข้าเงื่อนไข else และทำงานในส่วนของคำสั่งที่อยู่ภายใน else โดยพิมพ์ข้อความ \"Best Model: Gaussian Naive Bayes without Smoothing\""
      ],
      "metadata": {
        "id": "F2gNeCobWpzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "wQcFxXmbW4aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "X = digits['data']\n",
        "y = digits['target']\n",
        "# train_test_split จะใช้สุ่มแบ่ง X และ y เป็นชุดข้อมูลฝึกและชุดข้อมูลทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4, shuffle=True) #test_size=0.2 คือ 20% \n",
        "#กำหนด test_size เป็น 0.2 และกำหนด random_state เป็น 4 เพื่อให้การแบ่งชุดข้อมูลสามารถทำซ้ำได้และ shuffle เป็น True เพื่อสลับลำดับข้อมูลก่อนแบ่งชุด\n",
        "\n",
        "# Define parameter sets\n",
        "params_set_1 = {'n_neighbors': 3, 'weights': 'uniform'}\n",
        "params_set_2 = {'n_neighbors': 5, 'weights': 'distance'}\n",
        "\n",
        "# Train and test KNN models with parameter sets\n",
        "knn_1 = KNeighborsClassifier(**params_set_1)\n",
        "knn_1.fit(X_train, y_train)\n",
        "print('KNN 1 accuracy:', knn_1.score(X_test, y_test))\n",
        "\n",
        "knn_2 = KNeighborsClassifier(**params_set_2)\n",
        "knn_2.fit(X_train, y_train)\n",
        "print('KNN 2 accuracy:', knn_2.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "Bley43yaW0m9",
        "outputId": "bd2ffba0-a2d0-41c2-a93e-84bbd08c09fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN 1 accuracy: 0.9888888888888889\n",
            "KNN 2 accuracy: 0.9861111111111112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN"
      ],
      "metadata": {
        "id": "YKoZR614XAg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = digits['data']\n",
        "y = digits['target']\n",
        "# train_test_split จะใช้สุ่มแบ่ง X และ y เป็นชุดข้อมูลฝึกและชุดข้อมูลทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4, shuffle=True) #test_size=0.2 คือ 20% \n",
        "#กำหนด test_size เป็น 0.2 และกำหนด random_state เป็น 4 เพื่อให้การแบ่งชุดข้อมูลสามารถทำซ้ำได้และ shuffle เป็น True เพื่อสลับลำดับข้อมูลก่อนแบ่งชุด\n",
        "\n",
        "# กำหนด parameter sets ที่ต้องการทดสอบ\n",
        "#กำหนด parameter sets ที่ต้องการทดสอบโดยกำหนด hidden_layer_sizes เป็นจำนวนโหนดใน Hidden layer และกำหนด activation เป็นฟังก์ชัน Activation function \n",
        "#และกำหนด solver เป็น Algorithm สำหรับ optimization\n",
        "param_set_1 = {'hidden_layer_sizes': (50,), 'activation': 'logistic', 'solver': 'lbfgs'} \n",
        "param_set_2 = {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'adam'}\n",
        "\n",
        "# สร้างและ train โมเดล ANN สำหรับ parameter sets ที่กำหนด โดยใช้ MLPClassifier และ fit โมเดลด้วยข้อมูล X_train และ y_train\n",
        "\n",
        "model_1 = MLPClassifier(**param_set_1, random_state=42)\n",
        "model_1.fit(X_train, y_train)\n",
        "\n",
        "model_2 = MLPClassifier(**param_set_2, random_state=42)\n",
        "model_2.fit(X_train, y_train)\n",
        "\n",
        "# ประเมินประสิทธิภาพของโมเดล ANN กับ test set โดยใช้ predict เพื่อทำนายผลลัพธ์จากโมเดลและใช้ accuracy_score เพื่อคำนวณค่าความแม่นยำของโมเดล\n",
        "y_pred_1 = model_1.predict(X_test)\n",
        "accuracy_1 = accuracy_score(y_test, y_pred_1)\n",
        "\n",
        "y_pred_2 = model_2.predict(X_test)\n",
        "accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
        "\n",
        "#แสดงผลลัพธ์ค่าความแม่นยำของโมเดล ANN ของ parameter sets 1 และ 2\n",
        "print(f\"Accuracy for model 1 ANN1: {accuracy_1}\")\n",
        "print(f\"Accuracy for model 2 ANN2: {accuracy_2}\")"
      ],
      "metadata": {
        "id": "HPJDSUUyW65A",
        "outputId": "427ec579-378f-4f06-aa3a-830c78114666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for model 1 ANN1: 0.95\n",
            "Accuracy for model 2 ANN2: 0.9833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# รวม"
      ],
      "metadata": {
        "id": "5YvTzF9kXJMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "X = digits['data']\n",
        "y = digits['target']\n",
        "# train_test_split จะใช้สุ่มแบ่ง X และ y เป็นชุดข้อมูลฝึกและชุดข้อมูลทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4, shuffle=True) #test_size=0.2 คือ 20% \n",
        "#กำหนด test_size เป็น 0.2 และกำหนด random_state เป็น 4 เพื่อให้การแบ่งชุดข้อมูลสามารถทำซ้ำได้และ shuffle เป็น True เพื่อสลับลำดับข้อมูลก่อนแบ่งชุด\n",
        "\n",
        "#DT\n",
        "# Define parameter set 1\n",
        "params1 = {'criterion': 'gini', 'max_depth': 3}\n",
        "# Define parameter set 2\n",
        "params2 = {'criterion': 'entropy', 'max_depth': 5}\n",
        "# Create decision tree with parameter set 1\n",
        "dt1 = DecisionTreeClassifier(criterion=params1['criterion'], max_depth=params1['max_depth'])\n",
        "# Create decision tree with parameter set 2\n",
        "dt2 = DecisionTreeClassifier(criterion=params2['criterion'], max_depth=params2['max_depth'])\n",
        "# Evaluate the decision tree with parameter set 1\n",
        "accuracy1 = cross_val_score(dt1, digits.data, digits.target, cv=5).mean()\n",
        "# Evaluate the decision tree with parameter set 2\n",
        "accuracy2 = cross_val_score(dt2, digits.data, digits.target, cv=5).mean()\n",
        "# Compare the accuracies of the two models and choose the one with the highest accuracy\n",
        "if accuracy1 > accuracy2:\n",
        "    print(\"DT1 Parameter set 1 is better with an accuracy of\", accuracy1)\n",
        "else:\n",
        "    print(\"DT2 Parameter set 2 is better with an accuracy of\", accuracy2)\n",
        "\n",
        "#NaiveBayes\n",
        "# Parameter Set 1: Multinomial Naive Bayes with Laplace Smoothing\n",
        "mnb = MultinomialNB(alpha=1.0)\n",
        "mnb.fit(X_train, y_train)\n",
        "mnb_score = mnb.score(X_test, y_test)\n",
        "\n",
        "# Parameter Set 2: Gaussian Naive Bayes without Smoothing\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "gnb_score = gnb.score(X_test, y_test)\n",
        "\n",
        "# Print best model based on test set accuracy\n",
        "if mnb_score > gnb_score:\n",
        "    print(\"Best Model: Multinomial Naive Bayes with Laplace Smoothing\")\n",
        "    print(\"Test Accuracy: %0.2f\" % mnb_score)\n",
        "else:\n",
        "    print(\"Best Model: Gaussian Naive Bayes without Smoothing\")\n",
        "    print(\"Test Accuracy: %0.2f\" % gnb_score)\n",
        "\n",
        "#KNN\n",
        "# Define parameter sets\n",
        "params_set_1 = {'n_neighbors': 3, 'weights': 'uniform'}\n",
        "params_set_2 = {'n_neighbors': 5, 'weights': 'distance'}\n",
        "\n",
        "# Train and test KNN models with parameter sets\n",
        "knn_1 = KNeighborsClassifier(**params_set_1)\n",
        "knn_1.fit(X_train, y_train)\n",
        "print('KNN 1 accuracy:', knn_1.score(X_test, y_test))\n",
        "\n",
        "knn_2 = KNeighborsClassifier(**params_set_2)\n",
        "knn_2.fit(X_train, y_train)\n",
        "print('KNN 2 accuracy:', knn_2.score(X_test, y_test))\n",
        "\n",
        "#ANN\n",
        "# กำหนด parameter sets ที่ต้องการทดสอบ\n",
        "#กำหนด parameter sets ที่ต้องการทดสอบโดยกำหนด hidden_layer_sizes เป็นจำนวนโหนดใน Hidden layer และกำหนด activation เป็นฟังก์ชัน Activation function \n",
        "#และกำหนด solver เป็น Algorithm สำหรับ optimization\n",
        "param_set_1 = {'hidden_layer_sizes': (50,), 'activation': 'logistic', 'solver': 'lbfgs'} \n",
        "param_set_2 = {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'adam'}\n",
        "\n",
        "# สร้างและ train โมเดล ANN สำหรับ parameter sets ที่กำหนด โดยใช้ MLPClassifier และ fit โมเดลด้วยข้อมูล X_train และ y_train\n",
        "\n",
        "model_1 = MLPClassifier(**param_set_1, random_state=42)\n",
        "model_1.fit(X_train, y_train)\n",
        "\n",
        "model_2 = MLPClassifier(**param_set_2, random_state=42)\n",
        "model_2.fit(X_train, y_train)\n",
        "\n",
        "# ประเมินประสิทธิภาพของโมเดล ANN กับ test set โดยใช้ predict เพื่อทำนายผลลัพธ์จากโมเดลและใช้ accuracy_score เพื่อคำนวณค่าความแม่นยำของโมเดล\n",
        "y_pred_1 = model_1.predict(X_test)\n",
        "accuracy_1 = accuracy_score(y_test, y_pred_1)\n",
        "\n",
        "y_pred_2 = model_2.predict(X_test)\n",
        "accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
        "\n",
        "#แสดงผลลัพธ์ค่าความแม่นยำของโมเดล ANN ของ parameter sets 1 และ 2\n",
        "print(f\"Accuracy for model 1 ANN1: {accuracy_1}\")\n",
        "print(f\"Accuracy for model 2 ANN2: {accuracy_2}\")\n",
        "\n",
        "\n",
        "\n",
        "print('โมเดลที่ดีที่สุดคือ KNN 2 accuracy:', knn_2.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "R66uFXvPXDbx",
        "outputId": "c1953bf8-3ec0-4486-ce4f-8b3d7c01eac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT2 Parameter set 2 is better with an accuracy of 0.7334942742185083\n",
            "Best Model: Multinomial Naive Bayes with Laplace Smoothing\n",
            "Test Accuracy: 0.90\n",
            "KNN 1 accuracy: 0.9888888888888889\n",
            "KNN 2 accuracy: 0.9861111111111112\n",
            "Accuracy for model 1 ANN1: 0.95\n",
            "Accuracy for model 2 ANN2: 0.9833333333333333\n",
            "โมเดลที่ดีที่สุดคือ KNN 2 accuracy: 0.9861111111111112\n"
          ]
        }
      ]
    }
  ]
}